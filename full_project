import json
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime

Setting

with open('consolidated_full.json', 'r') as f:
    datastore = json.load(f)
with open('consolidated_full.json', 'r') as f:
    datastore = json.load(f)
    
# checking the keys 

datastore['bike_stations'][0]['bikes'][0]
datastore['bike_stations'][0]['bikes'][0]

datastore['timestamps']
datastore.keys()
dict_keys(['timestamps', 'bike_stations', 'scooters'])

# scooters is list of lists 
# bikes is a list of stations, each station is a dictionary
# checking dimensions

print('Scooters: ', np.array(datastore['scooters']).shape)
print('Bikes: ', np.array(datastore['bike_stations'][0]['bikes']).shape)

len(datastore['bike_stations'])

# data representation 
print(datastore['scooters'][0][0])
print(datastore['bike_stations'][0])

# creating list with bike stations
bikes = []
for i in range(len(datastore['bike_stations'])):
    single = [datastore['bike_stations'][i]['latitude'], datastore['bike_stations'][i]['longitude']]
    bikes.append(single)
    
# 455 bike stations
# 4817 timestamps 
# we can create a df with the number of bikes for each timestamp

rows = ['s_' + i['uid'] for i in datastore['bike_stations']]
list_data = [i['bikes'] for i in datastore['bike_stations']]
big_df = pd.DataFrame(data=list_data, index = rows).T
big_df.insert(loc=0, column='time', value=datastore['timestamps'])
# coverting unix format
big_df['time'] = big_df['time'].apply(lambda x: datetime.utcfromtimestamp(int(x)).strftime('%Y-%m-%d %H:%M:%S'))
# adding latitude and longitude
lon_lat = pd.DataFrame(bikes, index = rows, columns=['lat', 'lon']).T
big_df = lon_lat.append(big_df, sort=False)
big_df.tail()

Plotting
import folium
from folium.plugins import HeatMap
from folium.plugins import TimestampedGeoJson
from folium.plugins import HeatMapWithTime

Heatmaps for scooters

# creating a Map instance
m_scooters_heat = folium.Map(location=[60.17, 24.9], 
                             tiles="CartoDB dark_matter", 
                             zoom_start=13, 
                             control_scale=True)
# adding heatmap to map instance
HeatMap(datastore['scooters'][0]).add_to(m_scooters_heat)

# alternative syntax:
#m_scooters_heat.add_child(HeatMap(datastore['scooters'][0], radius=15))
m_scooters_heat

Maps for bikes

# plotting bikes for the first timestamp, experiment
num_1 = []
for i in range(len(datastore['bike_stations'])):
    single = datastore['bike_stations'][i]['bikes']
    num_1.append(single[0])
size_1 = []
for i in range(len(datastore['bike_stations'])):
    single = datastore['bike_stations'][i]['size']
    size_1.append(single)
df = pd.DataFrame(bikes, columns=['lat', 'lon'])
df['size'] = size_1
df['number'] = num_1
df['adj_num'] = df['number'] * 10 / df['size']
df['marker_color'] = pd.cut(df['adj_num'], bins=3, labels=['blue', 'orange', 'red'])
df.head()

m_bikes = folium.Map(location=[60.17, 24.9],
                     zoom_start=12, 
                     tiles="CartoDB dark_matter",
                     control_scale=True)
for index, row in df.iterrows():
    radius = row['adj_num']
    popup_text = """number of bikes: {}"""
    popup_text = popup_text.format(row["number"])   # adding interactive text (click on the marker to see)
    folium.CircleMarker([row['lat'], row['lon']],
                    radius=radius, color=row['marker_color'], fill=True, popup=popup_text).add_to(m_bikes)
m_bikes

Adding time to our maps

# creating an interactive heat map for scooters with timestamps
m_scooters_heat_with_time = folium.Map(location=[60.17, 24.9], 
                             tiles="CartoDB dark_matter", 
                             zoom_start=13, 
                             control_scale=True)
HeatMapWithTime(datastore['scooters'][:2000:12], 
               index = list(map(lambda x: datetime.fromtimestamp(x).strftime('%Y-%m-%d %H:%M:%S'), 
                                datastore['timestamps'][:2000:12]))).add_to(m_scooters_heat_with_time)

m_scooters_heat_with_time.save('scooters.html')
# creating an interactive map for bikes with timestamps
m_bikes_with_time = folium.Map(location=[60.22, 24.92],
                             tiles="CartoDB dark_matter",
                             zoom_start=12,
                             control_scale=True)
lats = list(map(lambda x: x['latitude'], datastore['bike_stations']))
lons = list(map(lambda x: x['longitude'], datastore['bike_stations']))
bikes = list(map(lambda x: x['bikes'][::12], datastore['bike_stations']))
empties = list(map(lambda x: x['empty_slots'][::12], datastore['bike_stations']))
times = datastore['timestamps'][::12]
features = []
for lat, lon, bs, es in zip(lats, lons, bikes, empties):
    for t, b, e in zip(times, bs, es):
        if e:
            rt = b/e
            x = rt/(rt+1)
        else:
            x = 1.0
        if x > 0.5:
            r = int((x-0.5)*2*255)
            b, g = 255-r, 0
            g = b
        else:
            g = int(x*2*255)
            b, r = 255-g, 0
            r = b
        c = "#{:0<2X}{:0<2X}{:0<2X}".format(r, g, 0)
        features.append({
             'type': 'Feature',
             'geometry': {
               'type': 'MultiPoint',
               'coordinates': [[lon,lat]]
               },
             'properties': {
               'times': [t*1000],
                'style': {'color': c},
                'icon': 'circle',
                        'iconstyle': {
                            'radius': 4,
                            'stroke': True,
                            'fillColor': c,
                            'fillOpacity': 1.0
                        }
               }
             })
TimestampedGeoJson({'type': 'FeatureCollection','features': features}, 
                   auto_play=False, 
                   loop=False, 
                   period='PT1H', 
                   duration='PT1H').add_to(m_bikes_with_time)


Problematic bike stations

import matplotlib.pyplot as plt
no_bikes_list = list(map(lambda x: x['bikes'].count(0), datastore['bike_stations']))
# stations which are empty more than half of the time
empty_stations = []
for i in range(len(no_bikes_list)):
    if no_bikes_list[i] > 2000:
        empty_stations.append(i)
empty_stations

# stations which are completely full more than half of the time
empty_slots_list = list(map(lambda x: x['empty_slots'].count(0), datastore['bike_stations']))
full_stations = []
for i in range(len(empty_slots_list)):
    if empty_slots_list[i] > 2000:
        full_stations.append(i)
full_stations

problematic_stations = folium.Map(location=[60.17, 24.9],
                     zoom_start=13, 
                     tiles="CartoDB dark_matter",
                     control_scale=True)
folium.CircleMarker(
    location=[datastore_full['bike_stations'][323]['latitude'], datastore_full['bike_stations'][323]['longitude']], 
    color = 'red', 
    radius = 15,
    popup = 'Name: Ruutikatu, Size: 11'
    ).add_to(problematic_stations)

locations_full = []
names_full = []
size_full = []
for i in full_stations:
    locations_full.append([datastore_full['bike_stations'][i]['latitude'], datastore_full['bike_stations'][i]['longitude']])
    names_full.append(datastore_full['bike_stations'][i]['name'])
    size_full.append(datastore_full['bike_stations'][i]['size'])
for i in range(len(locations_full)):
    folium.CircleMarker(
    location=locations_full[i],
    popup = ('Name: ' + names_full[i] + ', ' + 'Size: ' + str(size_full[i]))
    ).add_to(problematic_stations)
problematic_stations

def plot_bikes(df, x, y, title="", xlabel='Date', ylabel='Number of bikes', dpi=100):
    plt.figure(figsize=(16,5), dpi=dpi)
    plt.plot(x, y, color='tab:cyan')
    plt.xticks([])
    plt.gca().set(title=title, xlabel=xlabel, ylabel=ylabel)
    plt.show()
plot_bikes(big_df.iloc[2:,], x=big_df.iloc[2:,].time, y=big_df.iloc[2:,].s_767, title='Ruutikatu is almost always empty')   


for i in full_stations:
    plot_bikes(datastore['bike_stations'][i]['bikes'], x=big_df.iloc[2:,].time, y=datastore['bike_stations'][i]['bikes'], title=' ')    
for i in full_stations:
    plot_bikes(datastore['bike_stations'][i]['empty_slots'], x=big_df.iloc[2:,].time, y=datastore['bike_stations'][i]['empty_slots'], title=' ')    


Predicting demand
Predicting is important for effectively designing City Bikes locations and understanding where future bike stations should be installed.

from scipy.stats import gaussian_kde    # kernel-density estimate
import statsmodels.api as sm            # for representing result statistics
timestamps = datastore['timestamps'][2016::12]
stations = datastore['bike_stations']
scooters = datastore['scooters'][2016::12]
print(len(scooters))

weather = pd.read_csv('weather_data.csv')
weather = weather.fillna(method='ffill')                            # propagates last valid observation forward
weather_arr = np.array(weather.iloc[118+1008:2527:6])[:,-2:].astype(float) # cutting so it matches with our dataset length 
print(weather_arr.shape)

# weekday, hour, scooter density, station_mean, weather, last_week, mean_day, +3 for slots
X = np.zeros((len(timestamps), len(stations), 7 + 24 + 1 + 1 + 2 + 1 + 1 + 3))
y = np.zeros((len(timestamps), len(stations), 2)) # bikes, slots


for num, t in enumerate(timestamps):
    dt = datetime.fromtimestamp(t)
    weekday, hour = dt.weekday(), dt.hour  # creates categorical variables for days of the week and hours of the day
    densities = gaussian_kde(np.array(scooters[num]).T).pdf(station_coords)
    # estimates the probability density function for scooters variable 
    # and evaluates the estimated pdf on a provided set of points (locations)
    last_week = [station['bikes'][num*12] for station in stations]
    last_week_slots = [station['empty_slots'][num*12] for station in stations]
    station_means = np.array([np.mean(station['bikes'][num*12:num*12+2017:288]) for station in stations])
    station_means_slots = np.array([np.mean(station['empty_slots'][num*12:num*12+2017:288]) for station in stations])
    day_means = np.array([np.mean(station['bikes'][num*12:num*12+288]) for station in stations])
    day_means_slots = np.array([np.mean(station['empty_slots'][num*12:num*12+288]) for station in stations])
    #X[num, :, weekday] = 1
    X[num, :, 0] = 1 if weekday > 4 else 0  # the next lines fill in array with zeros created for X and y
    X[num, :, 7+hour] = 1
    X[num, :, 31] = densities
    X[num, :, 32] = station_means
    X[num, :, 33:35] = weather_arr[num]
    X[num, :, 35] = last_week
    X[num, :, 36] = day_means
    X[num, :, 37] = last_week_slots
    X[num, :, 38] = station_means_slots
    X[num, :, 39] = day_means_slots
    y[num, :, 0] = [station['bikes'][num*12+2016] for station in stations]
    y[num, :, 1] = [station['empty_slots'][num*12+2016] for station in stations]
    if num % 100 == 0:
        print(num) # just for process tracking


X = X.reshape((-1, 7 + 24 + 1 + 1 + 2 + 1 + 1 + 3)) # -1 stands for length of the array is set by numpy, providing we want 40 columns
y = y.reshape((-1, 2))  # ..., providing we want 2 column
print(X.shape)
print(y.shape)

OLS regression model
import statsmodels.api as sm # OLS regression with a constant 
sm_m_nbikes = sm.OLS(y[:,0], sm.add_constant(X))
sm_m_slots = sm.OLS(y[:,1], sm.add_constant(X))
print(sm_m_nbikes.fit().summary())
print(sm_m_slots.fit().summary())

RF regression model

from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import MinMaxScaler

Random Forest regression model without tuning parameters

model_rf = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)
results_rf_nbikes = model_rf.fit(X, y[:,0])
results_rf_nbikes.score(X, y[:,0])

results_rf_slots = model_rf.fit(X, y[:,1])
results_rf_slots.score(X, y[:,1])


gsc = GridSearchCV(
    estimator=RandomForestRegressor(),                                             # grid-search
    param_grid={'max_depth': range(3,7), 'n_estimators': (10, 50, 100, 500)},
    cv=5, 
    scoring='neg_mean_squared_error', 
    verbose=10, 
    n_jobs=-1)
grid_result = gsc.fit(X, y)

best_params = grid_result.best_params_
best_params

model_rf2 = RandomForestRegressor(max_depth=best_params["max_depth"], 
                                  n_estimators=best_params["n_estimators"], 
                                  random_state=False, verbose=False)
results_rf2_nbikes = model_rf2.fit(X, y[:,0])
results_rf2_nbikes.score(X, y[:,0])

results_rf2_slots = model_rf2.fit(X, y[:,1])
results_rf2_slots.score(X, y[:,1])

scores = cross_val_score(model_rf2, X, y, cv=10, scoring='neg_mean_absolute_error')    # cross-validation
scores

